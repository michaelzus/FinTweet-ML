{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 2: Feature Engineering Validation\n",
        "\n",
        "This notebook validates the feature engineering pipeline implemented in `tweet_classifier`.\n",
        "\n",
        "**Validates:**\n",
        "1. Data loading and column verification\n",
        "2. Reliable sample filtering\n",
        "3. Hash-based splitting with leakage verification\n",
        "4. Categorical encoding mappings\n",
        "5. TweetDataset creation with tokenizer\n",
        "6. Numerical feature scaling\n",
        "7. Class weight computation\n",
        "8. DataLoader batch iteration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Load Data and Verify Columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"../src\")\n",
        "\n",
        "from tweet_classifier.data.loader import load_enriched_data, get_data_summary\n",
        "from tweet_classifier.config import (\n",
        "    TARGET_COLUMN,\n",
        "    NUMERICAL_FEATURES,\n",
        "    CATEGORICAL_FEATURES,\n",
        "    EXCLUDED_FROM_FEATURES,\n",
        "    TEXT_COLUMN,\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 1: Load Data and Verify Columns\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load data\n",
        "df = load_enriched_data()\n",
        "print(f\"\\n✓ Loaded {len(df)} rows from enriched dataset\")\n",
        "\n",
        "# Verify required columns exist\n",
        "required_cols = [TARGET_COLUMN, TEXT_COLUMN, \"tweet_hash\", \"is_reliable_label\"]\n",
        "required_cols.extend(NUMERICAL_FEATURES)\n",
        "required_cols.extend(CATEGORICAL_FEATURES)\n",
        "\n",
        "print(f\"\\n--- Required Columns Check ---\")\n",
        "all_present = True\n",
        "for col in required_cols:\n",
        "    present = col in df.columns\n",
        "    status = \"✓\" if present else \"✗ MISSING\"\n",
        "    print(f\"  {status} {col}\")\n",
        "    all_present = all_present and present\n",
        "\n",
        "if all_present:\n",
        "    print(\"\\n✓ All required columns present\")\n",
        "else:\n",
        "    print(\"\\n✗ Some required columns missing!\")\n",
        "\n",
        "# Show data summary\n",
        "summary = get_data_summary(df)\n",
        "print(f\"\\n--- Data Summary ---\")\n",
        "for key, value in summary.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Filter to Reliable Samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tweet_classifier.data.loader import filter_reliable\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 2: Filter to Reliable Samples\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Filter data\n",
        "df_reliable = filter_reliable(df, drop_missing_target=True)\n",
        "\n",
        "print(f\"\\nBefore filtering: {len(df)} samples\")\n",
        "print(f\"After filtering:  {len(df_reliable)} samples\")\n",
        "print(f\"Removed: {len(df) - len(df_reliable)} samples ({100*(len(df) - len(df_reliable))/len(df):.1f}%)\")\n",
        "\n",
        "# Verify no missing targets\n",
        "missing_targets = df_reliable[TARGET_COLUMN].isna().sum()\n",
        "print(f\"\\nMissing targets after filter: {missing_targets}\")\n",
        "assert missing_targets == 0, \"Filter should have removed all missing targets!\"\n",
        "print(\"✓ No missing targets in filtered data\")\n",
        "\n",
        "# Verify all samples are reliable\n",
        "unreliable = (~df_reliable[\"is_reliable_label\"]).sum()\n",
        "print(f\"Unreliable samples after filter: {unreliable}\")\n",
        "assert unreliable == 0, \"Filter should have removed all unreliable samples!\"\n",
        "print(\"✓ All samples are reliable\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Split by Hash, Verify No Leakage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tweet_classifier.data.splitter import split_by_hash, get_split_summary, verify_no_leakage\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 3: Split by Hash, Verify No Leakage\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Split data\n",
        "df_train, df_val, df_test = split_by_hash(df_reliable)\n",
        "\n",
        "# Get summary\n",
        "split_summary = get_split_summary(df_train, df_val, df_test)\n",
        "\n",
        "print(f\"\\n--- Split Summary ---\")\n",
        "print(f\"{'Set':<10} {'Samples':>10} {'Percentage':>12} {'Unique Hashes':>15}\")\n",
        "print(\"-\" * 50)\n",
        "for split_name in [\"train\", \"val\", \"test\"]:\n",
        "    s = split_summary[split_name]\n",
        "    print(f\"{split_name:<10} {s['samples']:>10} {s['percentage']:>11.1f}% {s['unique_hashes']:>15}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Total':<10} {split_summary['total']:>10}\")\n",
        "\n",
        "# Verify no leakage\n",
        "print(\"\\n--- Leakage Verification ---\")\n",
        "try:\n",
        "    verify_no_leakage(df_train, df_val, df_test)\n",
        "    print(\"✓ No hash overlap between train/val/test splits\")\n",
        "    print(\"✓ No text leakage detected\")\n",
        "except ValueError as e:\n",
        "    print(f\"✗ LEAKAGE DETECTED: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Create Categorical Encodings, Verify Mappings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tweet_classifier.dataset import create_categorical_encodings, encode_categorical\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 4: Create Categorical Encodings, Verify Mappings\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create encodings from training data only (to avoid leakage)\n",
        "encodings = create_categorical_encodings(df_train)\n",
        "\n",
        "print(f\"\\n--- Author Encoding ---\")\n",
        "print(f\"Number of unique authors: {encodings['num_authors']}\")\n",
        "print(f\"\\nTop 5 author mappings:\")\n",
        "for author, idx in list(encodings['author_to_idx'].items())[:5]:\n",
        "    print(f\"  {idx}: {author}\")\n",
        "\n",
        "print(f\"\\n--- Category Encoding ---\")\n",
        "print(f\"Number of unique categories: {encodings['num_categories']}\")\n",
        "print(f\"\\nCategory mappings:\")\n",
        "for category, idx in encodings['category_to_idx'].items():\n",
        "    print(f\"  {idx}: {category}\")\n",
        "\n",
        "# Apply encodings to train set\n",
        "df_train_encoded = encode_categorical(\n",
        "    df_train,\n",
        "    encodings['author_to_idx'],\n",
        "    encodings['category_to_idx'],\n",
        "    handle_unknown='default'\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Verification ---\")\n",
        "print(f\"✓ author_idx column added: {'author_idx' in df_train_encoded.columns}\")\n",
        "print(f\"✓ category_idx column added: {'category_idx' in df_train_encoded.columns}\")\n",
        "print(f\"\\nSample encoded rows:\")\n",
        "print(df_train_encoded[['author', 'author_idx', 'category', 'category_idx']].head(3).to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Create TweetDataset with Tokenizer, Verify Shapes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from tweet_classifier.dataset import create_dataset_from_df\n",
        "from tweet_classifier.config import FINBERT_MODEL_NAME, MAX_TEXT_LENGTH\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 5: Create TweetDataset with Tokenizer, Verify Shapes\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load tokenizer\n",
        "print(f\"\\nLoading tokenizer: {FINBERT_MODEL_NAME}\")\n",
        "tokenizer = BertTokenizer.from_pretrained(FINBERT_MODEL_NAME)\n",
        "print(f\"✓ Tokenizer loaded (vocab size: {tokenizer.vocab_size})\")\n",
        "\n",
        "# Create dataset from training data\n",
        "print(f\"\\nCreating TweetDataset from {len(df_train)} training samples...\")\n",
        "train_dataset, scaler = create_dataset_from_df(\n",
        "    df_train,\n",
        "    tokenizer,\n",
        "    encodings['author_to_idx'],\n",
        "    encodings['category_to_idx'],\n",
        "    scaler=None,\n",
        "    fit_scaler=True\n",
        ")\n",
        "\n",
        "print(f\"✓ Dataset created with {len(train_dataset)} samples\")\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"\\n--- Tensor Shapes (single sample) ---\")\n",
        "sample = train_dataset[0]\n",
        "for key, tensor in sample.items():\n",
        "    print(f\"  {key}: {tensor.shape}\")\n",
        "\n",
        "# Verify expected shapes\n",
        "print(f\"\\n--- Shape Verification ---\")\n",
        "assert sample['input_ids'].shape[0] == MAX_TEXT_LENGTH, f\"Expected {MAX_TEXT_LENGTH} tokens\"\n",
        "print(f\"✓ input_ids: [{MAX_TEXT_LENGTH}] (max_length={MAX_TEXT_LENGTH})\")\n",
        "\n",
        "assert sample['attention_mask'].shape[0] == MAX_TEXT_LENGTH\n",
        "print(f\"✓ attention_mask: [{MAX_TEXT_LENGTH}]\")\n",
        "\n",
        "assert sample['numerical'].shape[0] == len(NUMERICAL_FEATURES)\n",
        "print(f\"✓ numerical: [{len(NUMERICAL_FEATURES)}] ({NUMERICAL_FEATURES})\")\n",
        "\n",
        "assert sample['author_idx'].shape == ()\n",
        "print(f\"✓ author_idx: scalar\")\n",
        "\n",
        "assert sample['category_idx'].shape == ()\n",
        "print(f\"✓ category_idx: scalar\")\n",
        "\n",
        "assert sample['labels'].shape == ()\n",
        "print(f\"✓ labels: scalar (0=SELL, 1=HOLD, 2=BUY)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Verify Numerical Features are Scaled Correctly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 6: Verify Numerical Features are Scaled Correctly\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get all numerical features from dataset\n",
        "all_numerical = train_dataset.numerical.numpy()\n",
        "\n",
        "print(f\"\\n--- Numerical Features Statistics ---\")\n",
        "print(f\"Shape: {all_numerical.shape} (samples x features)\")\n",
        "\n",
        "print(f\"\\n{'Feature':<25} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n",
        "print(\"-\" * 70)\n",
        "for i, feat_name in enumerate(NUMERICAL_FEATURES):\n",
        "    col = all_numerical[:, i]\n",
        "    print(f\"{feat_name:<25} {col.mean():>10.4f} {col.std():>10.4f} {col.min():>10.4f} {col.max():>10.4f}\")\n",
        "\n",
        "# Verify scaling (StandardScaler should give mean~0, std~1)\n",
        "print(f\"\\n--- Scaling Verification ---\")\n",
        "mean_close_to_zero = np.allclose(all_numerical.mean(axis=0), 0, atol=0.1)\n",
        "std_close_to_one = np.allclose(all_numerical.std(axis=0), 1, atol=0.2)\n",
        "\n",
        "if mean_close_to_zero:\n",
        "    print(\"✓ Feature means are close to 0 (StandardScaler applied)\")\n",
        "else:\n",
        "    print(\"⚠️  Feature means deviate from 0\")\n",
        "\n",
        "if std_close_to_one:\n",
        "    print(\"✓ Feature stds are close to 1 (StandardScaler applied)\")\n",
        "else:\n",
        "    print(\"⚠️  Feature stds deviate from 1\")\n",
        "\n",
        "# Verify scaler was fitted\n",
        "print(f\"\\n--- Scaler Parameters ---\")\n",
        "print(f\"Scaler mean_: {scaler.mean_}\")\n",
        "print(f\"Scaler scale_: {scaler.scale_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Verify Class Weights Match Expected Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tweet_classifier.data.weights import compute_class_weights, get_weight_summary, weights_to_tensor\n",
        "from tweet_classifier.config import LABEL_MAP_INV\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 7: Verify Class Weights Match Expected Distribution\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get weight summary\n",
        "weight_summary = get_weight_summary(df_train[TARGET_COLUMN])\n",
        "\n",
        "print(f\"\\n--- Class Distribution and Weights ---\")\n",
        "print(f\"{'Class':<10} {'Count':>10} {'Percentage':>12} {'Weight':>10}\")\n",
        "print(\"-\" * 45)\n",
        "total = sum(w['count'] for w in weight_summary.values())\n",
        "for label, info in weight_summary.items():\n",
        "    pct = 100 * info['count'] / total if total > 0 else 0\n",
        "    print(f\"{label:<10} {info['count']:>10} {pct:>11.1f}% {info['weight']:>10.4f}\")\n",
        "\n",
        "# Compute weights\n",
        "weights = compute_class_weights(df_train[TARGET_COLUMN])\n",
        "weights_tensor = weights_to_tensor(weights)\n",
        "\n",
        "print(f\"\\n--- Weight Verification ---\")\n",
        "print(f\"Computed weights (numpy): {weights}\")\n",
        "print(f\"Computed weights (tensor): {weights_tensor}\")\n",
        "\n",
        "# Verify inverse relationship: higher weight for minority class\n",
        "class_counts = [weight_summary[LABEL_MAP_INV[i]]['count'] for i in range(3)]\n",
        "min_class_idx = np.argmin(class_counts)\n",
        "max_weight_idx = np.argmax(weights)\n",
        "\n",
        "if min_class_idx == max_weight_idx:\n",
        "    print(f\"\\n✓ Minority class ({LABEL_MAP_INV[min_class_idx]}) has highest weight ({weights[min_class_idx]:.4f})\")\n",
        "else:\n",
        "    print(f\"\\n⚠️  Weight assignment may be incorrect\")\n",
        "\n",
        "# Verify weights are balanced (mean should be ~1)\n",
        "mean_weight = weights.mean()\n",
        "print(f\"\\nMean weight: {mean_weight:.4f} (should be ~1.0 for balanced weights)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: Test DataLoader Iteration (Batch Shapes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tweet_classifier.config import DEFAULT_BATCH_SIZE\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CELL 8: Test DataLoader Iteration (Batch Shapes)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=DEFAULT_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0  # Set to 0 for notebook compatibility\n",
        ")\n",
        "\n",
        "print(f\"\\nDataLoader created:\")\n",
        "print(f\"  Batch size: {DEFAULT_BATCH_SIZE}\")\n",
        "print(f\"  Total batches: {len(train_loader)}\")\n",
        "print(f\"  Total samples: {len(train_dataset)}\")\n",
        "\n",
        "# Get first batch\n",
        "print(f\"\\n--- First Batch Shapes ---\")\n",
        "batch = next(iter(train_loader))\n",
        "for key, tensor in batch.items():\n",
        "    print(f\"  {key}: {tensor.shape}\")\n",
        "\n",
        "# Verify batch shapes\n",
        "print(f\"\\n--- Batch Shape Verification ---\")\n",
        "B = DEFAULT_BATCH_SIZE\n",
        "\n",
        "assert batch['input_ids'].shape == (B, MAX_TEXT_LENGTH)\n",
        "print(f\"✓ input_ids: [{B}, {MAX_TEXT_LENGTH}]\")\n",
        "\n",
        "assert batch['attention_mask'].shape == (B, MAX_TEXT_LENGTH)\n",
        "print(f\"✓ attention_mask: [{B}, {MAX_TEXT_LENGTH}]\")\n",
        "\n",
        "assert batch['numerical'].shape == (B, len(NUMERICAL_FEATURES))\n",
        "print(f\"✓ numerical: [{B}, {len(NUMERICAL_FEATURES)}]\")\n",
        "\n",
        "assert batch['author_idx'].shape == (B,)\n",
        "print(f\"✓ author_idx: [{B}]\")\n",
        "\n",
        "assert batch['category_idx'].shape == (B,)\n",
        "print(f\"✓ category_idx: [{B}]\")\n",
        "\n",
        "assert batch['labels'].shape == (B,)\n",
        "print(f\"✓ labels: [{B}]\")\n",
        "\n",
        "# Iterate through a few batches to verify no errors\n",
        "print(f\"\\n--- Batch Iteration Test ---\")\n",
        "num_test_batches = min(5, len(train_loader))\n",
        "for i, batch in enumerate(train_loader):\n",
        "    if i >= num_test_batches:\n",
        "        break\n",
        "print(f\"✓ Successfully iterated through {num_test_batches} batches without errors\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PHASE 2 FEATURE ENGINEERING VALIDATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll checks passed! The feature engineering pipeline is working correctly.\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"  1. Implement FinBERTMultiModal model (Phase 3)\")\n",
        "print(\"  2. Create training script (Phase 4)\")\n",
        "print(\"  3. Train and evaluate (Phase 5)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
