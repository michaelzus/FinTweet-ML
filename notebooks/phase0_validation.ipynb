{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 0: Pre-Training Validation\n",
        "\n",
        "This notebook validates the enriched data before FinBERT training.\n",
        "\n",
        "**Checks performed:**\n",
        "1. Feature leakage (no future-looking columns in features)\n",
        "2. Target distribution (class imbalance)\n",
        "3. Author bias analysis\n",
        "4. Data quality metrics\n",
        "5. Premarket risk assessment\n",
        "6. Optional: Sentiment signal check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Setup and Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load enriched data\n",
        "df = pd.read_csv(\"../output/15-dec-enrich7.csv\")\n",
        "\n",
        "# Global configuration (from FINBERT_TRAINING_PLAN.md)\n",
        "TARGET_COLUMN = \"label_1d_3class\"\n",
        "\n",
        "NUMERICAL_FEATURES = [\n",
        "    \"volatility_7d\",\n",
        "    \"relative_volume\",\n",
        "    \"rsi_14\",\n",
        "    \"distance_from_ma_20\",\n",
        "]\n",
        "\n",
        "FORBIDDEN_AS_FEATURES = [\n",
        "    \"spy_return_1d\",\n",
        "    \"spy_return_1hr\",\n",
        "    \"return_1hr\",\n",
        "    \"price_1hr_after\",\n",
        "    \"return_to_next_open\",\n",
        "    \"price_next_open\",\n",
        "]\n",
        "\n",
        "print(f\"Loaded {len(df)} rows with {len(df.columns)} columns\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Feature Leakage Check\n",
        "\n",
        "Verify that no future-looking columns are in the feature set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"FEATURE LEAKAGE CHECK\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check 1: No forbidden columns in NUMERICAL_FEATURES\n",
        "leakage_found = False\n",
        "for col in FORBIDDEN_AS_FEATURES:\n",
        "    if col in NUMERICAL_FEATURES:\n",
        "        print(f\"❌ LEAK: {col} found in NUMERICAL_FEATURES!\")\n",
        "        leakage_found = True\n",
        "\n",
        "if not leakage_found:\n",
        "    print(\"✓ No future columns in NUMERICAL_FEATURES\")\n",
        "\n",
        "# Check 2: Specifically verify spy_return_1d exclusion\n",
        "assert \"spy_return_1d\" not in NUMERICAL_FEATURES, \"LEAK: spy_return_1d uses day T close!\"\n",
        "print(\"✓ spy_return_1d correctly excluded from features\")\n",
        "\n",
        "# Display what IS included vs excluded\n",
        "print(f\"\\n--- Features to be used (safe) ---\")\n",
        "for f in NUMERICAL_FEATURES:\n",
        "    exists = f in df.columns\n",
        "    status = \"✓\" if exists else \"⚠️ MISSING\"\n",
        "    print(f\"  {status} {f}\")\n",
        "\n",
        "print(f\"\\n--- Columns excluded (future-looking) ---\")\n",
        "for f in FORBIDDEN_AS_FEATURES:\n",
        "    exists = f in df.columns\n",
        "    status = \"(in data, excluded)\" if exists else \"(not in data)\"\n",
        "    print(f\"  ✓ {f} {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Target Distribution\n",
        "\n",
        "Check class distribution for `label_1d_3class` (expecting ~61% HOLD based on plan).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(f\"TARGET DISTRIBUTION ({TARGET_COLUMN})\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Value counts\n",
        "target_dist = df[TARGET_COLUMN].value_counts()\n",
        "target_pct = df[TARGET_COLUMN].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"\\nAbsolute counts:\")\n",
        "print(target_dist)\n",
        "\n",
        "print(\"\\nPercentages:\")\n",
        "for label, pct in target_pct.items():\n",
        "    print(f\"  {label}: {pct:.1f}%\")\n",
        "\n",
        "# Check for missing targets\n",
        "missing_target = df[TARGET_COLUMN].isna().sum()\n",
        "print(f\"\\nMissing targets: {missing_target} ({100*missing_target/len(df):.1f}%)\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Bar chart\n",
        "colors = {'SELL': '#e74c3c', 'HOLD': '#95a5a6', 'BUY': '#27ae60'}\n",
        "target_dist.plot(kind='bar', ax=axes[0], color=[colors.get(x, '#3498db') for x in target_dist.index])\n",
        "axes[0].set_title(f'{TARGET_COLUMN} Distribution')\n",
        "axes[0].set_xlabel('Label')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Pie chart\n",
        "target_dist.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
        "                 colors=[colors.get(x, '#3498db') for x in target_dist.index])\n",
        "axes[1].set_title('Class Balance')\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Imbalance warning\n",
        "max_class_pct = target_pct.max()\n",
        "if max_class_pct > 60:\n",
        "    print(f\"\\n⚠️  WARNING: Class imbalance detected ({max_class_pct:.1f}% in majority class)\")\n",
        "    print(\"   → Use class weights in training loss function\")\n",
        "else:\n",
        "    print(\"\\n✓ Class distribution is reasonably balanced\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Author Bias Analysis\n",
        "\n",
        "Check author distribution (plan notes 2 authors = 65% of data).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"AUTHOR BIAS ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "author_dist = df[\"author\"].value_counts()\n",
        "author_pct = df[\"author\"].value_counts(normalize=True) * 100\n",
        "\n",
        "print(f\"\\nTotal unique authors: {df['author'].nunique()}\")\n",
        "print(\"\\nTop 5 authors:\")\n",
        "for i, (author, count) in enumerate(author_dist.head(5).items()):\n",
        "    pct = author_pct[author]\n",
        "    print(f\"  {i+1}. {author}: {count} tweets ({pct:.1f}%)\")\n",
        "\n",
        "# Top 2 authors combined\n",
        "top2_pct = author_pct.head(2).sum()\n",
        "print(f\"\\nTop 2 authors combined: {top2_pct:.1f}%\")\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "author_dist.head(10).plot(kind='barh', ax=ax, color='#3498db')\n",
        "ax.set_title('Top 10 Authors by Tweet Count')\n",
        "ax.set_xlabel('Number of Tweets')\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bias warning\n",
        "if top2_pct > 50:\n",
        "    print(f\"\\n⚠️  WARNING: Author concentration detected ({top2_pct:.1f}% from top 2)\")\n",
        "    print(\"   → Add author embedding to model to control for author bias\")\n",
        "    print(\"   → Consider stratified sampling by author\")\n",
        "else:\n",
        "    print(\"\\n✓ Author distribution is reasonably diverse\")\n",
        "\n",
        "# Check label distribution per top author\n",
        "print(\"\\n--- Label distribution by top 3 authors ---\")\n",
        "for author in author_dist.head(3).index:\n",
        "    author_labels = df[df[\"author\"] == author][TARGET_COLUMN].value_counts(normalize=True) * 100\n",
        "    print(f\"\\n{author}:\")\n",
        "    for label, pct in author_labels.items():\n",
        "        print(f\"  {label}: {pct:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Data Quality Metrics\n",
        "\n",
        "Check total samples, reliable labels, and valid 1-day labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"DATA QUALITY METRICS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "total_samples = len(df)\n",
        "\n",
        "# Reliable labels\n",
        "if \"is_reliable_label\" in df.columns:\n",
        "    df_reliable = df[df[\"is_reliable_label\"] == True]\n",
        "    reliable_count = len(df_reliable)\n",
        "else:\n",
        "    df_reliable = df\n",
        "    reliable_count = total_samples\n",
        "    print(\"⚠️  'is_reliable_label' column not found, using all samples\")\n",
        "\n",
        "# Valid 1-day labels\n",
        "valid_1d_labels = df[TARGET_COLUMN].notna().sum()\n",
        "\n",
        "# Summary table\n",
        "print(f\"\\n{'Metric':<30} {'Count':>10} {'Percentage':>12}\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Total samples':<30} {total_samples:>10} {'100.0%':>12}\")\n",
        "print(f\"{'Reliable 1hr labels':<30} {reliable_count:>10} {100*reliable_count/total_samples:>11.1f}%\")\n",
        "print(f\"{'With 1-day labels':<30} {valid_1d_labels:>10} {100*valid_1d_labels/total_samples:>11.1f}%\")\n",
        "\n",
        "# Check numerical features for missing values\n",
        "print(\"\\n--- Missing values in numerical features ---\")\n",
        "for col in NUMERICAL_FEATURES:\n",
        "    if col in df.columns:\n",
        "        missing = df[col].isna().sum()\n",
        "        pct = 100 * missing / total_samples\n",
        "        status = \"✓\" if pct < 5 else \"⚠️\"\n",
        "        print(f\"  {status} {col}: {missing} missing ({pct:.1f}%)\")\n",
        "\n",
        "# Text quality\n",
        "print(\"\\n--- Text quality ---\")\n",
        "if \"text\" in df.columns:\n",
        "    empty_text = (df[\"text\"].isna() | (df[\"text\"].str.strip() == \"\")).sum()\n",
        "    avg_text_len = df[\"text\"].str.len().mean()\n",
        "    print(f\"  Empty/missing text: {empty_text}\")\n",
        "    print(f\"  Average text length: {avg_text_len:.0f} chars\")\n",
        "\n",
        "# Recommendation\n",
        "print(f\"\\n=== RECOMMENDATION ===\")\n",
        "print(f\"Use {reliable_count} reliable samples for training\")\n",
        "print(f\"Filter: df_train = df[df['is_reliable_label'] == True]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Premarket Risk Assessment\n",
        "\n",
        "Premarket tweets have the highest leakage risk (technical indicators may use future data).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"PREMARKET RISK ASSESSMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if \"session\" in df.columns:\n",
        "    session_dist = df[\"session\"].value_counts()\n",
        "    session_pct = df[\"session\"].value_counts(normalize=True) * 100\n",
        "    \n",
        "    print(\"\\nTweets by session:\")\n",
        "    for session, count in session_dist.items():\n",
        "        pct = session_pct[session]\n",
        "        risk = \"⚠️ HIGH RISK\" if session == \"premarket\" else \"\"\n",
        "        print(f\"  {session}: {count} ({pct:.1f}%) {risk}\")\n",
        "    \n",
        "    # Visualization\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    colors_session = {'premarket': '#e74c3c', 'market': '#27ae60', 'afterhours': '#3498db'}\n",
        "    session_dist.plot(kind='bar', ax=ax, \n",
        "                      color=[colors_session.get(x, '#95a5a6') for x in session_dist.index])\n",
        "    ax.set_title('Tweets by Session')\n",
        "    ax.set_xlabel('Session')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.tick_params(axis='x', rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Premarket warning\n",
        "    premarket_count = session_dist.get(\"premarket\", 0)\n",
        "    premarket_pct = 100 * premarket_count / len(df)\n",
        "    \n",
        "    print(f\"\\n=== PREMARKET ANALYSIS ===\")\n",
        "    print(f\"Premarket tweets: {premarket_count} ({premarket_pct:.1f}%)\")\n",
        "    \n",
        "    if premarket_pct > 10:\n",
        "        print(f\"\\n⚠️  WARNING: {premarket_pct:.1f}% premarket tweets\")\n",
        "        print(\"   For these, technical indicators (RSI, volatility) use day T close (FUTURE DATA)\")\n",
        "        print(\"   Options:\")\n",
        "        print(\"   1. CONSERVATIVE: df_clean = df[df['session'] != 'premarket']\")\n",
        "        print(\"   2. ACCEPT: Minor leakage (~1%), indicators change slowly day-to-day\")\n",
        "    else:\n",
        "        print(\"✓ Low premarket exposure, acceptable for training\")\n",
        "        \n",
        "else:\n",
        "    print(\"⚠️  'session' column not found in data\")\n",
        "    print(\"   Cannot assess premarket risk\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Optional - Sentiment Signal Check\n",
        "\n",
        "Quick check to see if there's any correlation between text sentiment and returns.\n",
        "\n",
        "**Note:** Requires `transformers` library and may take a few minutes to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set to True to run sentiment analysis (requires transformers, takes ~5 mins)\n",
        "RUN_SENTIMENT_CHECK = False\n",
        "\n",
        "if RUN_SENTIMENT_CHECK:\n",
        "    try:\n",
        "        from transformers import pipeline\n",
        "        \n",
        "        print(\"Loading FinBERT sentiment model...\")\n",
        "        sentiment = pipeline(\"sentiment-analysis\", model=\"yiyanghkust/finbert-tone\")\n",
        "        \n",
        "        # Sample 100 tweets for quick check\n",
        "        df_sample = df.dropna(subset=[\"text\", \"return_to_next_open\"]).sample(min(100, len(df)), random_state=42)\n",
        "        \n",
        "        print(f\"Analyzing {len(df_sample)} sample tweets...\")\n",
        "        \n",
        "        def get_sentiment_score(text):\n",
        "            try:\n",
        "                result = sentiment(str(text)[:512])[0]\n",
        "                label_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "                return label_map.get(result['label'].lower(), 0)\n",
        "            except Exception:\n",
        "                return 0\n",
        "        \n",
        "        df_sample[\"sentiment_score\"] = df_sample[\"text\"].apply(get_sentiment_score)\n",
        "        \n",
        "        # Calculate correlation\n",
        "        corr = df_sample[\"sentiment_score\"].corr(df_sample[\"return_to_next_open\"])\n",
        "        \n",
        "        print(f\"\\n=== SENTIMENT SIGNAL CHECK ===\")\n",
        "        print(f\"Sentiment-return correlation: {corr:.4f}\")\n",
        "        \n",
        "        if abs(corr) > 0.05:\n",
        "            print(f\"✓ Positive signal detected! Correlation = {corr:.4f}\")\n",
        "        else:\n",
        "            print(f\"⚠️  Weak signal (correlation = {corr:.4f})\")\n",
        "            print(\"   This is expected - FinBERT needs fine-tuning on this data\")\n",
        "            \n",
        "    except ImportError:\n",
        "        print(\"⚠️  transformers library not installed\")\n",
        "        print(\"   Run: pip install transformers\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during sentiment check: {e}\")\n",
        "else:\n",
        "    print(\"Sentiment check skipped (set RUN_SENTIMENT_CHECK = True to enable)\")\n",
        "    print(\"Note: This requires the transformers library and takes ~5 minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Final validation summary and recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"PHASE 0 VALIDATION SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Collect all checks\n",
        "checks = []\n",
        "\n",
        "# 1. Leakage check\n",
        "leakage_ok = all(col not in NUMERICAL_FEATURES for col in FORBIDDEN_AS_FEATURES)\n",
        "checks.append((\"Feature Leakage\", \"PASS\" if leakage_ok else \"FAIL\", leakage_ok))\n",
        "\n",
        "# 2. Target availability\n",
        "target_available = df[TARGET_COLUMN].notna().sum() / len(df) > 0.5\n",
        "checks.append((\"Target Availability\", f\"{100*df[TARGET_COLUMN].notna().sum()/len(df):.0f}%\", target_available))\n",
        "\n",
        "# 3. Class balance (warn if >70% in one class)\n",
        "max_class = df[TARGET_COLUMN].value_counts(normalize=True).max()\n",
        "balance_ok = max_class < 0.70\n",
        "checks.append((\"Class Balance\", f\"{100*max_class:.0f}% max\", balance_ok))\n",
        "\n",
        "# 4. Author diversity\n",
        "top2_authors = df[\"author\"].value_counts(normalize=True).head(2).sum()\n",
        "author_ok = True  # Always OK if we use author embeddings\n",
        "checks.append((\"Author Embedding Needed\", f\"{100*top2_authors:.0f}% top 2\", True))\n",
        "\n",
        "# 5. Data quality\n",
        "if \"is_reliable_label\" in df.columns:\n",
        "    reliable_pct = df[\"is_reliable_label\"].sum() / len(df)\n",
        "else:\n",
        "    reliable_pct = 1.0\n",
        "quality_ok = reliable_pct > 0.5\n",
        "checks.append((\"Reliable Labels\", f\"{100*reliable_pct:.0f}%\", quality_ok))\n",
        "\n",
        "# Print summary table\n",
        "print(f\"\\n{'Check':<25} {'Result':>15} {'Status':>10}\")\n",
        "print(\"-\" * 52)\n",
        "for name, result, ok in checks:\n",
        "    status = \"✓\" if ok else \"⚠️\"\n",
        "    print(f\"{name:<25} {result:>15} {status:>10}\")\n",
        "\n",
        "# Overall verdict\n",
        "all_pass = all(ok for _, _, ok in checks)\n",
        "print(\"\\n\" + \"=\" * 52)\n",
        "if all_pass:\n",
        "    print(\"✓ ALL CHECKS PASSED - Data is ready for training!\")\n",
        "else:\n",
        "    print(\"⚠️  Some checks need attention (see warnings above)\")\n",
        "\n",
        "# Recommended filtering\n",
        "print(f\"\\n=== RECOMMENDED DATA FILTERING ===\")\n",
        "print(f\"df_train = df[df['is_reliable_label'] == True].dropna(subset=['{TARGET_COLUMN}'])\")\n",
        "print(f\"Expected training samples: ~{int(reliable_pct * df[TARGET_COLUMN].notna().sum())}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
